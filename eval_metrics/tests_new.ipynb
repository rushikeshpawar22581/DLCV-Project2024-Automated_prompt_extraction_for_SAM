{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(true_mask, predicted_mask):\n",
    "    # Convert true mask to gray scale\n",
    "    true_mask_gray = cv2.cvtColor(true_mask, cv2.COLOR_BGR2GRAY)\n",
    "    # Convert predicted mask to gray scale\n",
    "    predicted_mask_gray = cv2.cvtColor(predicted_mask, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    intersection = np.logical_and(true_mask_gray, predicted_mask_gray)\n",
    "    union = np.logical_or(true_mask_gray, predicted_mask_gray)\n",
    "\n",
    "    iou = np.sum(intersection) / np.sum(union)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dice_score(true_mask, predicted_mask):\n",
    "    # Ensure the masks are binary\n",
    "    true_mask_binary = true_mask > 0\n",
    "    predicted_mask_binary = predicted_mask > 0\n",
    "    \n",
    "    intersection = np.logical_and(true_mask_binary, predicted_mask_binary)\n",
    "\n",
    "    dice_score = 0\n",
    "\n",
    "    # Calculate Dice score only if both true and predicted masks are present\n",
    "    if np.sum(true_mask_binary) > 0 and np.sum(predicted_mask_binary) > 0:\n",
    "        # Calculate intersection area\n",
    "        intersection_area = np.sum(intersection)\n",
    "        # Calculate area of true mask\n",
    "        true_area = np.sum(true_mask_binary)\n",
    "        # Calculate area of predicted mask\n",
    "        predicted_area = np.sum(predicted_mask_binary)\n",
    "        \n",
    "        # Calculate Dice score\n",
    "        dice_score = 2 * intersection_area / (true_area + predicted_area)\n",
    "    else:\n",
    "        dice_score = 0\n",
    "\n",
    "    return dice_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pixel wise accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pixel wise accuracy\n",
    "\n",
    "def calculate_pixel_wise_accuracy(true_mask, predicted_mask):\n",
    "    \n",
    "    #convert true mask to gray scale\n",
    "    true_mask_gray=cv2.cvtColor(true_mask,cv2.COLOR_BGR2GRAY)\n",
    "    #convert predicted mask to gray scale\n",
    "    predicted_mask_gray=cv2.cvtColor(predicted_mask,cv2.COLOR_BGR2GRAY)\n",
    "    #calculate pixel wise accuracy\n",
    "    #number of pixels in true mask\n",
    "    true_positive=np.sum((true_mask_gray==255) & (predicted_mask_gray==255))\n",
    "    false_positive=np.sum((true_mask_gray==0) & (predicted_mask_gray==255))\n",
    "    false_negative=np.sum((true_mask_gray==255) & (predicted_mask_gray==0))\n",
    "    true_negative=np.sum((true_mask_gray==0) & (predicted_mask_gray==0))\n",
    "\n",
    "\n",
    "    #pixel wise accuracy\n",
    "    pixel_wise_accuracy=(true_positive+true_negative)/(true_positive+true_negative+false_positive+false_negative)\n",
    "\n",
    "    return pixel_wise_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name of folder to eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name='BreastSAM impl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(benign_gt_dir, benign_predictions_dir,csv_file_name):\n",
    "    list_of_benign_predictions_dir = os.listdir(benign_predictions_dir)\n",
    "\n",
    "    df = pd.DataFrame(columns=['File', 'IOU', 'Dice Score', 'Pixel Wise Accuracy'])\n",
    "\n",
    "    for files in list_of_benign_predictions_dir:\n",
    "        # read true mask\n",
    "        #print(files)\n",
    "        true_mask = cv2.imread(os.path.join(benign_gt_dir, files.replace('_mask_prediction.png', '_mask.png')))\n",
    "        # read predicted mask\n",
    "        predicted_mask = cv2.imread(os.path.join(benign_predictions_dir, files))\n",
    "\n",
    "        # calculate iou\n",
    "        iou = calculate_iou(true_mask, predicted_mask)\n",
    "        # calculate dice score\n",
    "        dice_score = calculate_dice_score(true_mask, predicted_mask)\n",
    "        # calculate pixel wise accuracy\n",
    "        pixel_wise_accuracy = calculate_pixel_wise_accuracy(true_mask, predicted_mask)\n",
    "\n",
    "        df.loc[len(df)] = [files, iou, dice_score, pixel_wise_accuracy]\n",
    "\n",
    "\n",
    "    # save the dataframe to a csv file\n",
    "    df.to_csv(csv_file_name, index=False)\n",
    "    \n",
    "    print('Metrics saved to ',csv_file_name)\n",
    "    average_dice_score=np.mean(df['Dice Score'])\n",
    "    average_iou=np.mean(df['IOU'])\n",
    "    average_pixel_wise_accuracy=np.mean(df['Pixel Wise Accuracy'])\n",
    "    \n",
    "    return average_dice_score,average_iou,average_pixel_wise_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only box prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to  ..\\BreastSAM impl\\benign_box_metrics.csv\n",
      "Average Dice Score: 0.8639273011884666\n",
      "Average IOU: 0.7751496027403703\n",
      "Average Pixel Wise Accuracy: 0.9836931349911328\n"
     ]
    }
   ],
   "source": [
    "benign_predictions_dir=os.path.join('..', folder_name, 'SAM_predictions_BBox', 'benign')\n",
    "benign_gt_dir=os.path.join('..','Dataset_BUSI_with_GT','benign')\n",
    "\n",
    "average_dice_score,average_iou,average_pixel_wise_accuracy=calculate_metrics(benign_gt_dir,benign_predictions_dir,os.path.join('..',folder_name,'benign_box_metrics.csv'))\n",
    "\n",
    "print('Average Dice Score:',average_dice_score)\n",
    "print('Average IOU:',average_iou)\n",
    "print('Average Pixel Wise Accuracy:',average_pixel_wise_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to  ..\\BreastSAM impl\\malignant_box_metrics.csv\n",
      "Average Dice Score: 0.8231403836728571\n",
      "Average IOU: 0.7083671832802122\n",
      "Average Pixel Wise Accuracy: 0.954822882845514\n"
     ]
    }
   ],
   "source": [
    "malignant_predictions_dir=os.path.join('..', folder_name, 'SAM_predictions_BBox', 'malignant')\n",
    "malignant_gt_dir=os.path.join('..','Dataset_BUSI_with_GT','malignant')\n",
    "\n",
    "average_dice_score,average_iou,average_pixel_wise_accuracy=calculate_metrics(malignant_gt_dir,malignant_predictions_dir,os.path.join('..',folder_name,'malignant_box_metrics.csv'))\n",
    "\n",
    "print('Average Dice Score:',average_dice_score)\n",
    "print('Average IOU:',average_iou)\n",
    "print('Average Pixel Wise Accuracy:',average_pixel_wise_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with box and point prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to  ..\\BreastSAM impl\\benign_point_box_metrics.csv\n",
      "Average Dice Score: 0.8771654120817105\n",
      "Average IOU: 0.79010434918551\n",
      "Average Pixel Wise Accuracy: 0.9844730317006107\n"
     ]
    }
   ],
   "source": [
    "benign_gt_dir=os.path.join('..','Dataset_BUSI_with_GT','benign')\n",
    "benign_point_box_dir=os.path.join('..',folder_name,'SAM_predictions_BBoxPoint','benign')\n",
    "\n",
    "average_dice_score,average_iou,average_pixel_wise_accuracy=calculate_metrics(benign_gt_dir,benign_point_box_dir,os.path.join('..',folder_name,'benign_point_box_metrics.csv'))\n",
    "\n",
    "print('Average Dice Score:',average_dice_score)\n",
    "print('Average IOU:',average_iou)\n",
    "print('Average Pixel Wise Accuracy:',average_pixel_wise_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to  ..\\BreastSAM impl\\malignant_point_box_metrics.csv\n",
      "Average Dice Score: 0.8304638058228664\n",
      "Average IOU: 0.7155563276327351\n",
      "Average Pixel Wise Accuracy: 0.9551953264603636\n"
     ]
    }
   ],
   "source": [
    "malignant_gt_dir=os.path.join('..','Dataset_BUSI_with_GT','malignant')\n",
    "malignant_point_box_dir=os.path.join('..',folder_name,'SAM_predictions_BBoxPoint','malignant')\n",
    "\n",
    "average_dice_score,average_iou,average_pixel_wise_accuracy=calculate_metrics(malignant_gt_dir,malignant_point_box_dir,os.path.join('..',folder_name,'malignant_point_box_metrics.csv'))\n",
    "\n",
    "print('Average Dice Score:',average_dice_score)\n",
    "print('Average IOU:',average_iou)\n",
    "print('Average Pixel Wise Accuracy:',average_pixel_wise_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to  ..\\BreastSAM impl\\benign_point_metrics.csv\n",
      "Average Dice Score: 0.6771114339553682\n",
      "Average IOU: 0.5896810091898083\n",
      "Average Pixel Wise Accuracy: 0.896623810514078\n"
     ]
    }
   ],
   "source": [
    "benign_gt_dir=os.path.join('..','Dataset_BUSI_with_GT','benign')\n",
    "benign_point_box_dir=os.path.join('..',folder_name,'SAM_predictions_Point','benign')\n",
    "\n",
    "average_dice_score,average_iou,average_pixel_wise_accuracy=calculate_metrics(benign_gt_dir,benign_point_box_dir,os.path.join('..',folder_name,'benign_point_metrics.csv'))\n",
    "\n",
    "print('Average Dice Score:',average_dice_score)\n",
    "print('Average IOU:',average_iou)\n",
    "print('Average Pixel Wise Accuracy:',average_pixel_wise_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to  ..\\BreastSAM impl\\malignant_point_metrics.csv\n",
      "Average Dice Score: 0.5883291313479885\n",
      "Average IOU: 0.46138997781788166\n",
      "Average Pixel Wise Accuracy: 0.8071209403626128\n"
     ]
    }
   ],
   "source": [
    "malignant_gt_dir=os.path.join('..','Dataset_BUSI_with_GT','malignant')\n",
    "malignant_point_box_dir=os.path.join('..',folder_name,'SAM_predictions_Point','malignant')\n",
    "\n",
    "average_dice_score,average_iou,average_pixel_wise_accuracy=calculate_metrics(malignant_gt_dir,malignant_point_box_dir,os.path.join('..',folder_name,'malignant_point_metrics.csv'))\n",
    "\n",
    "print('Average Dice Score:',average_dice_score)\n",
    "print('Average IOU:',average_iou)\n",
    "print('Average Pixel Wise Accuracy:',average_pixel_wise_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
