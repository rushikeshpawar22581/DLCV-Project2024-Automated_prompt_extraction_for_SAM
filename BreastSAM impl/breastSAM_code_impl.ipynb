{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment to install segment anything and other dependencies\n",
    "# !pip install git+https://github.com/facebookresearch/segment-anything.git\n",
    "# !pip install opencv-python pycocotools matplotlib onnxruntime onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "import os\n",
    "import gc\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "SAM_CHECKPOINT = os.path.join('..','SAM model','sam_vit_l_0b3195.pth')\n",
    "MODEL_TYPE = 'vit_l'\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "sam_model = sam_model_registry[MODEL_TYPE](checkpoint=SAM_CHECKPOINT)\n",
    "sam_model = sam_model.to(DEVICE)\n",
    "sam_promt2mask = SamPredictor(sam_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "benign_dataframe_path = os.path.join('..','Dataset_BUSI_with_GT','benign_bounding_box.csv')\n",
    "malignant_dataframe_path = os.path.join('..','Dataset_BUSI_with_GT','malignant_bounding_box.csv')\n",
    "\n",
    "benign_dataframe = pd.read_csv(benign_dataframe_path)\n",
    "malignant_dataframe = pd.read_csv(malignant_dataframe_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the benign dataframe\n",
    "benign_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.utils.transforms import ResizeLongestSide\n",
    "resize_transform = ResizeLongestSide(sam_model.image_encoder.img_size)\n",
    "\n",
    "# prepare image by resizing and converting to tensor\n",
    "def prepare_image(image, transform, model):\n",
    "    image = transform.apply_image(image)\n",
    "    image = torch.as_tensor(image, device=model.device) \n",
    "    return image.permute(2, 0, 1).contiguous()\n",
    "\n",
    "# define to prepare batch of images\n",
    "def batch_dataloader(data_frame, batch_size, prompt , shuffle=True, model=sam_model, random_state=None):\n",
    "    batch = []\n",
    "    indices = []\n",
    "    # shuffle the data\n",
    "    if shuffle:\n",
    "        data_frame = data_frame.sample(frac=1, random_state=random_state)\n",
    "\n",
    "    for i, row in data_frame.iterrows():\n",
    "        img_path = os.path.join('..',row['path'])\n",
    "        # read the image and convert to RGB\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        og_size = image.shape[:2]\n",
    "\n",
    "        # prepare the image\n",
    "        image = prepare_image(image, resize_transform, model)\n",
    "\n",
    "        # read the bounding box\n",
    "        bbox = torch.tensor([row['x_min'], row['y_min'], row['x_max'], row['y_max']]).view(1, 4)\n",
    "        bbox = bbox.to(model.device)\n",
    "        bbox = resize_transform.apply_boxes_torch(bbox, og_size)\n",
    "\n",
    "        if prompt =='BBox+Point' or prompt =='Point':\n",
    "            # read point prompts\n",
    "            point_coords = torch.tensor([row['center_x'], row['center_y']]).view(1, 1, 2)\n",
    "            point_coords = resize_transform.apply_coords_torch(point_coords, og_size)  \n",
    "            point_coords = point_coords.to(model.device)\n",
    "\n",
    "            point_labels = torch.tensor(1).view(1, 1)\n",
    "            point_labels = point_labels.to(model.device)\n",
    "            \n",
    "            if prompt =='BBox+Point':\n",
    "                # create dictionary\n",
    "                img_dict = {\n",
    "                    'image': image, \n",
    "                    'boxes': bbox,\n",
    "                    'original_size': og_size,\n",
    "                    'point_coords': point_coords,\n",
    "                    'point_labels': point_labels,\n",
    "                }\n",
    "            \n",
    "            else:\n",
    "                # create dictionary\n",
    "                img_dict = {\n",
    "                    'image': image,\n",
    "                    'point_coords': point_coords,\n",
    "                    'point_labels': point_labels,\n",
    "                    'original_size': og_size,\n",
    "                }\n",
    "            \n",
    "        elif prompt == 'BBox':\n",
    "            # create dictionary\n",
    "            img_dict = {\n",
    "                'image': image,\n",
    "                'boxes': bbox,\n",
    "                'original_size': og_size\n",
    "            }\n",
    "        else:\n",
    "            raise ValueError('prompt should be either BBox, BBox+Point or Point')\n",
    "        \n",
    "        indices.append(i)\n",
    "        batch.append(img_dict)\n",
    "\n",
    "        if len(batch) == batch_size:\n",
    "            yield indices,batch\n",
    "            batch = []\n",
    "            indices = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if images, boxes and points are transformed correctly\n",
    "import matplotlib.patches as patches\n",
    "for batch,item in batch_dataloader(malignant_dataframe, 1, 'BBox+Point', shuffle=True, random_state=None):\n",
    "    item=item[0]\n",
    "\n",
    "    img = item['image'].cpu()\n",
    "    boxes = item['boxes']\n",
    "    point_coords = item['point_coords'].cpu().numpy().squeeze().squeeze()\n",
    "    point_labels = item['point_labels']\n",
    "\n",
    "    fig,ax = plt.subplots(1)\n",
    "    ax.imshow(img.permute(1, 2, 0))\n",
    "    for box in boxes:\n",
    "        box = box.cpu().numpy()\n",
    "        rect = patches.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1], linewidth=1, edgecolor='r', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "    ax.scatter(point_coords[0],point_coords[1])\n",
    "    ax.axis('off')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_vram():\n",
    "    if DEVICE == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to unpack batched output and save the masks\n",
    "def unpack_and_save_op(indices, batch_op, data_frame,save_dir):\n",
    "    '''\n",
    "    indices: list of indices in original data_frame\n",
    "    batch_op: list of output dictionaries\n",
    "    data_frame: original data_frame\n",
    "    save_dir: directory to save the output masks\n",
    "    '''\n",
    "    # Check if save_dir exists, create it if it doesn't\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    for i, index in enumerate(indices):\n",
    "        # get the row for index\n",
    "        row = data_frame.iloc[index]\n",
    "\n",
    "        # get the output dictionary\n",
    "        op_dict = batch_op[i]\n",
    "\n",
    "        # get the mask\n",
    "        mask = op_dict['masks'].squeeze().cpu().numpy()\n",
    "\n",
    "        # save mask to given directory with name in dafaframe with added prediction word\n",
    "        mask_path = os.path.join(save_dir, row['image'].replace('mask.png', 'mask_prediction.png'))\n",
    "\n",
    "        # save the mask\n",
    "        plt.imsave(mask_path, mask, cmap='gray')\n",
    "\n",
    "        # clear the memory\n",
    "        del op_dict\n",
    "        clear_vram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear vram before starting\n",
    "clear_vram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only BBox prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save = os.path.join('SAM_predictions_BBox','benign')\n",
    "with tqdm.tqdm(total=len(benign_dataframe)) as pbar:\n",
    "    for indices, batch in batch_dataloader(benign_dataframe,2,prompt='BBox',shuffle=False):\n",
    "        with torch.no_grad():\n",
    "            batch_op = sam_model(batch, multimask_output = False)\n",
    "            clear_vram()\n",
    "            unpack_and_save_op(indices, batch_op, benign_dataframe,path_to_save) \n",
    "        pbar.update(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save = os.path.join('SAM_predictions_BBox','malignant')\n",
    "with tqdm.tqdm(total=len(malignant_dataframe)) as pbar:\n",
    "    for indices, batch in batch_dataloader(malignant_dataframe,2,prompt='BBox',shuffle=False):\n",
    "        with torch.no_grad():\n",
    "            batch_op = sam_model(batch, multimask_output = False)\n",
    "            clear_vram()\n",
    "            unpack_and_save_op(indices, batch_op, malignant_dataframe, path_to_save)\n",
    "        pbar.update(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear vram \n",
    "clear_vram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only Point prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save = os.path.join('SAM_predictions_Point','benign')\n",
    "with tqdm.tqdm(total=len(benign_dataframe)) as pbar:\n",
    "    for indices, batch in batch_dataloader(benign_dataframe,2,prompt='Point',shuffle=False):\n",
    "        with torch.no_grad():\n",
    "            batch_op = sam_model(batch, multimask_output = False)\n",
    "            clear_vram()\n",
    "            unpack_and_save_op(indices, batch_op, benign_dataframe,path_to_save) \n",
    "        pbar.update(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save = os.path.join('SAM_predictions_Point','malignant')\n",
    "with tqdm.tqdm(total=len(malignant_dataframe)) as pbar:\n",
    "    for indices, batch in batch_dataloader(malignant_dataframe,2,prompt='Point',shuffle=False):\n",
    "        with torch.no_grad():\n",
    "            batch_op = sam_model(batch, multimask_output = False)\n",
    "            clear_vram()\n",
    "            unpack_and_save_op(indices, batch_op, malignant_dataframe, path_to_save)\n",
    "        pbar.update(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear vram \n",
    "clear_vram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BBox+Point prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save = os.path.join('SAM_predictions_BBoxPoint','benign')\n",
    "with tqdm.tqdm(total=len(benign_dataframe)) as pbar:\n",
    "    for indices, batch in batch_dataloader(benign_dataframe,2,prompt='BBox+Point',shuffle=False):\n",
    "        with torch.no_grad():\n",
    "            batch_op = sam_model(batch, multimask_output = False)\n",
    "            clear_vram()\n",
    "            unpack_and_save_op(indices, batch_op, benign_dataframe,path_to_save) \n",
    "        pbar.update(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save = os.path.join('SAM_predictions_BBoxPoint','malignant')\n",
    "with tqdm.tqdm(total=len(malignant_dataframe)) as pbar:\n",
    "    for indices, batch in batch_dataloader(malignant_dataframe,2,prompt='BBox+Point',shuffle=False):\n",
    "        with torch.no_grad():\n",
    "            batch_op = sam_model(batch, multimask_output = False)\n",
    "            clear_vram()\n",
    "            unpack_and_save_op(indices, batch_op, malignant_dataframe, path_to_save)\n",
    "        pbar.update(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear vram \n",
    "clear_vram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
